[{"id":0,"href":"/neural-analyis-notes/","title":"Possible neural analyses to compare CO and CST","section":"CST Strategy Project Notes","content":"Possible neural analyses to compare CO and CST tasks #  Single neuron analyses #  List of analyses that we can use to compare CO and CST on a single neuron level\n Averages  ❓ How does average firing rate change across tasks?  📊 Analysis: compare averages across tasks   ❓ How does average firing rate change between hold and movement, within and across tasks?  📊 Analysis: Hold vs. move activity within and across tasks     PSTHs  ❓ Do PSTHs in CST look like CO?  📊 Analysis: Calculate PSTHs for hold-\u0026gt;move submovements in CST     Tuning curves  ❓ How similar is single neural tuning between CO and CST?  📊 Analysis: Compare left/right selectivity between CO and CST  ✔️ Note: This is basically the sensorimotor index analysis, which showed similar tuning between the tasks   📊 Analysis: Fit GLMs and examine how parameters shift between CO and CST  ❗ Note/caution: neural GLMs are usually noisy and tricky to glean interpretation from        Population analyses #  List of population analysis methods we could use to compare CO and CST\n Neural covariance  ❓ Because CST has smaller movements, does neural variance also decrease as much as you would expect?  📊 Analysis: compare total neural variance between CO and CST ✔️ CST usually has smaller variance than CO, but unclear yet if it\u0026rsquo;s what we would expect from smaller movements ❓ Remiaining question: is this variance solely due to smaller movements? Not sure how to address this question though.   ❓ CST seems like a more complex task than CO\u0026ndash;does this mean that neural activity explores more dimensions?  📊 compare CO and CST covariance rank (i.e. dimensionality)  ✔️ CST does not seem to have much higher dimensionality, but activity is much closer to noise floor 💬 Three methods of dimensionality estimation (participation ratio, parallel analysis, and GPFA cross-validated log-likelihood) give differing results     ❓ How much do CST and CO overlap in the neural manifold?  📊 compare neural covariance dimensions between CO and CST, using subspace overlap or principle angles     Subspace analysis  ❓ Is there a neural \u0026ldquo;go\u0026rdquo; signal underlying intermittent movements/control?  📊 Condition independent signal analysis  💬 It\u0026rsquo;s difficult to pull out a meaningful CIS at a single trial level, even for CO task. We probably need a method for trial-averaging CST to make use of this (like submovement decomposition)     ❓ is there a dimension of neural activity corresponding to neural engagement? Perhaps something that corresponds to whether $\\lambda$ changed on the last trial, or whether there have been previous failures?  📊 Analyze major neural dimensions during hold period after failures and $\\lambda$ changes   📊 Behaviorally potent/null space analysis  ❓ Do CO and CST share a kinematic potent space? (use principle angles and subspace alignment)  ✔️ Sudarshan\u0026rsquo;s and my own analysis suggests that potent spaces are at least partially aligned   ❓ How much neural variance lies in the potent and null spaces of each task, compared to total neural variance? ❓ Is there any correspondence between the timing of null space activation and movement?  💬 Note: our arrays don\u0026rsquo;t seem to have preparatory activity, which is what you\u0026rsquo;d expect to find in the null space. But there may be some information about visual feedback, if we can isolate feedback integration times   ❓ What does the null space activity look like during BCI CST, where potent space is specified?  💬 Aaron says that BCI data might not be great? Need to check with Emily     ❓ Are there dimensions of neural activity that separate CO and CST?  ✔️ Hold time analysis says possibly in the very early part of the movement, but perhaps this is due to kinematic differences? ❓ if there\u0026rsquo;s a task context dimension, how aligned with kinematic potent space is it? Perhaps this dimension separates different motor cortical dynamic regimes?     Neural dynamics  📊 Tangling analysis  ❓ CST is much more feedback driven than CO. Does this show up as M1 dynamics being less apparently autonomous? That is, is neural tangling higher in CST than CO?  ✔️ Tangling doesn\u0026rsquo;t really appear to be much higher in CST than CO, suggesting that the feedback may be \u0026ldquo;predictable\u0026rdquo; most of the time. 💬 Does tangling depend on the amount of data you use to check it? Right now I\u0026rsquo;m thinking it probably does, but I can\u0026rsquo;t be sure without simulation   ❓ Does the timecourse of tangling over a CST or CO trial reveal anything about corrective movements? Perhaps tangling increases before corrective movements or after apparent errors to signify introduction of unexpected feedback.  💬 May need to develop corrective movement detection to enable trial averaging, as well as apparent error detection (for CST, this might equate to moving the hand in the wrong direction)     📊 Neural dynamic modeling  ❓ Does CST contain different neural dynamical regimes? e.g. movement vs. hold/preparation  ❗ CO seems to have different regimes, according to previous work, but CST data seems a bit too noisy as is   ❓ Does CST have autonomous and input-driven times in neural dynamics? That is, if we infer inputs to a neural dynamical system (AutoLFADS), do the inputs look similar between movement initiation and submovements?  💬 Other work suggests movement initiation and corrective movements share features like condition independent signal and inferred inputs        Cross-over analyses #  List of sophisticated behavioral analyses that could be run on neural data\n 📊 Contraction analysis  "},{"id":1,"href":"/neural-analyis-notes/20211209-covariance-analysis/","title":"CO-CST covariance analysis","section":"Possible neural analyses to compare CO and CST","content":"2021/12/09 CO-CST covariance analysis #  For neural covariance analysis, we have a number of possible questions:\n ❓ Because CST has smaller movements, does neural variance also decrease as much as you would expect?  📊 Analysis: compare total neural variance between CO and CST ✔️ CST usually has smaller variance than CO, but unclear yet if it\u0026rsquo;s what we would expect from smaller movements ❓ Remiaining question: is this variance solely due to smaller movements? Not sure how to address this question though.   ❓ CST seems like a more complex task than CO\u0026ndash;does this mean that neural activity explores more dimensions?  📊 compare CO and CST covariance rank (i.e. dimensionality), using participation ratio, parallel analysis, and GPFA cross-validated log-likelihood  ✔️ CST does not seem to have much higher dimensionality, but activity is much closer to noise floor 💬 Three methods of dimensionality estimation (participation ratio, parallel analysis, and GPFA cross-validated log-likelihood) give differing results     ❓ How much do CST and CO overlap in the neural manifold?  📊 compare neural covariance dimensions between CO and CST, using subspace overlap or principle angles    I examined the first two questions together, during the movement period of both CO and CST (figures below). Important to note: I calculated all of these after softnorming neural activity within each task ($\\alpha$=5). No smoothing applied. Applying these techniques without the softnorm gives similar results for variance, though parallel analysis results are noisier (probably due to high variability of a few neurons). Reasonable levels of smoothing doesn\u0026rsquo;t change any of these results much, though I would guess that oversmoothing data would decrease dimensionality.\nNeural Variance #  Despite the within-task softnorm, the total neural variance seems much lower for CST than CO (top plots, CO in red, CST in black). Variance for individual lambdas of the CST (solid line) doesn\u0026rsquo;t seem to be much different from the variance over all lambdas (black dashed line). Remaining question: is this difference in variance more or less than what we would expect from the different kinematics of the two tasks? CST movements are much smaller than CO movements on average, so we might expect a much lower neural variance to start with.\nNeural dimensionality #  The same plots above show two measures of dimensionality: the participation ratio, which a measure of how flat the eigenspectrum of a covariance matrix is (flat eigenspectrum would have PR equal to the number of neurons), and parallel analysis dimensionality, which constructs a null distribution of eigenspectra by shuffling neural activity independently across time. The upshot is that PR says that the eigenspectra of both tasks are remarkably flat (when neurons are softnormed at least), but PA suggests that both tasks have significant covariance in only a few dimensions. Notably, when evaluated at individual $\\lambda$, the PA dimensionality (black solid line) is very similar to the CO dimensionality (red dashed line), while CST dimensionality when evaluated over all $\\lambda$ (black dashed line) is notably higher (though unclear if this difference is statistically significant). The most mundane explanation for this difference is that when you add more data, you get higher estimated dimensionality (see Surya Ganguli\u0026rsquo;s work and Ryan Williamson\u0026rsquo;s work). A less mundane explanation might be that you use different, not fully overlapping dimensions of neural activity at different $\\lambda$, but this claim seems unlikely.\nBelow are some eigenspectra for CO and CST movement-time activity for both monkeys, with 95th percentile null distribution from parallel analysis.\nGPFA dimensionality estimation #  We can also evaluate the dimensionality using GPFA cross-validated log-likelihood across number of factors used to describe the data. For this dataset, it has been a little tricky to fairly compare CO and CST, since generally there\u0026rsquo;s so much more CST data than CO. But just pushing the data through the pipeline, we get these figures (note that these data were not softnormed before running GPFA, and this particular analysis takes hours to run):\nThis suggests that CST does indeed have higher dimensionality than CO. However, when we select only the number of CST trials (each 6 seconds long) to match the total number of time points across tasks, we get this for CST:\nAnd that seems to suggest a similar dimensionality between the two tasks.\nBut we can also match both number of trials and number of timepoints in each tasks, subselecting one 0.5 s portion of each CST trial to match the CO trials:\nAnd that gives something mostly nonsensical. Haven\u0026rsquo;t quite figured this one out yet, but I think the overall story is just that CST and CO have similar dimensionality, and everything weird here is just measurement error.\nHold time analyses #  I also ran all of these analyses (except the GPFA analysis) on the hold time before movement in both tasks. Here are those figures:\nThe scales are a little bit off (note that variance y-axis has quite tiny range compared to previous figures), but basically, variance and dimensionality were pretty much the same in the hold period of CO and CST. Also, Ford\u0026rsquo;s neural data during hold period is quite noisy, as shown by his hold-time eigenspectra being close to the noise.\n"},{"id":2,"href":"/neural-analyis-notes/20211209-cis-analysis/","title":"CO Condition independent signal analysis","section":"Possible neural analyses to compare CO and CST","content":"2021/12/09 Condition independent signal analysis #  ❓ Is there a neural \u0026ldquo;go\u0026rdquo; signal underlying intermittent movements/control?\nOne result out of the literature recently has been that there are condition-independent signals (CIS) in neural activity that don\u0026rsquo;t relate to the exact movement being performed, but rather as a signal of whether a movement is being performed at all (see Kaufman et al. 2016, Rouse et al. 2018, Zimnik and Churchland 2021). The signal seems like a kind of neural \u0026ldquo;go\u0026rdquo; signal\u0026ndash;it\u0026rsquo;s one thing we might be able to look for in CST as a marker of corrective or intermittent movements.\nFirst, though, we need to see if we can find the CIS in CO on a single trial level\u0026ndash;most, if not all previous work with the CIS has been using trial-averaged data, and since we can\u0026rsquo;t readily do that with CST, we\u0026rsquo;d like to be able to find the CIS in single CO trials.\nThe results are unfortunately mostly negative\u0026ndash;though the CIS dimensions are clearly there in a trial average, it\u0026rsquo;s very difficult to see on single trials (see figures below).\nSo if we want to pull out a CIS from CST trials, we\u0026rsquo;ll need to find a way to average across movements. Perhaps we could take the first 500ms of each CST trial, or we could run some submovement decomposition to pull out hold and move states.\n"},{"id":3,"href":"/neural-analyis-notes/20211210-engagement-analysis/","title":"CST neural engagement","section":"Possible neural analyses to compare CO and CST","content":"2021/12/10 Neural engagement analysis in CST #  ❓ Is there a dimension of neural activity corresponding to neural engagement? Perhaps something that corresponds to whether $\\lambda$ changed on the last trial, or whether there have been previous failures?\nIn Hennig et al. 2021, they found a neural dimension corresponding to engagement with the BCI task. When there were changes in the task (e.g. the decoder changes), activity along this axis increases and then slowly decreases over a series of trials.\nThey found this axis separately for each target direction during a BCI center-out task\u0026ndash;they defined it as the dimension along which neural activity had the most variance for trials to that specific target. This also happened to line up nicely with the \u0026ldquo;ones\u0026rdquo; axis, the axis along which most, if not all, neural loadings were positive and similar to each other.\nAaron has a vague memory of a previous master\u0026rsquo;s student finding some kind of change in neural activity after $\\lambda$ changed in CST\u0026ndash;might there be a neural engagement signal in this task too?\nSince we don\u0026rsquo;t really have targets in CST, our next best bet was to look at the activity during the hold period\u0026ndash;perhaps there would be some large variance dimensions of neural activity that could correspond to whether the $\\lambda$ changed within the last couple trials, or the number of previous failures in the task. Below are figures plotting the first three PCs of average hold time activity during CST (note: neural activity was softnormed here)\nIn these figures, top plot shows the $\\lambda$ for each trial as a color (where the actual value is given by the color bar at the top\u0026hellip; it\u0026rsquo;s a little confusing). The red dashed lines indicate trials on which the monkey failed the task. Other three plots show average hold time activity in PC 1, 2, or 3, where each dot represents one trial, colored by its $\\lambda$. For Earl, there seems to be a slow drift in PC1 , possibly related to lambda changes or failures, but it could also be related to disinterest in the task\u0026ndash;hard to say without randomized $\\lambda$. Other than that, I can\u0026rsquo;t really see a correspondence between hold time activity and $\\lambda$ changes or failures.\nOne way to check this out a bit more is to try to predict either the $\\lambda$ on the previous trial or the number of previous failures from the hold time activity. Figures below:\nAgain, slight correlation in Earl with $\\lambda$ on previous trial, but this might be due to the slow drift.\nNo real correlation here unfortunately.\nOne possible followup for this engagement work is just to look at the mean firing rate across neurons for each trial to see if there\u0026rsquo;s anything that jumps out\u0026ndash;since the engagement axis in the Hennig paper was mainly in the \u0026ldquo;ones\u0026rdquo; axis, maybe a straight average across normed neurons will pull something from the noise.\nIf we try to look for engagement in neural population during the movement phase of CST, one thing we might have to contend with is the monkey\u0026rsquo;s arm movements (which weren\u0026rsquo;t present in the BCI task in the Hennig paper), but perhaps we can just fit a linear model between neural activity and arm movement and then just look at the null space of that to take out the majority of arm-related neural signals.\n"},{"id":4,"href":"/neural-analyis-notes/20211210-hold-analysis/","title":"CO-CST hold time analysis","section":"Possible neural analyses to compare CO and CST","content":"2021/12/10 Hold time neural analysis #   ❓ Are there dimensions of neural activity that separate CO and CST?  ✔️ Hold time analysis says possibly in the very early part of the movement, but perhaps this is due to kinematic differences?    Gallego et al. 2018 showed that M1 neural activity underlying multiple tasks shared some dimensions of neural activity, but also that there were certain dimensions of activity that separated different tasks. Though the tasks differed in the impedance of wrist movement (ranging from isometric to freely moving), the tasks were quite comparable: they were all wrist-based tasks with similar trial structure, where the monkey moved a cursor to visually presented targets within a set amount of time.\nIf we want to compare CO and CST in the same way, our best bet to start with is to compare neural activity during the hold period, when the instructions and hand kinematics are roughly the same between tasks. Simply plotting the hold time neural activity in the top PCs initially showed that there was a great separability between CO and CST hold-time neural state, despite there not being as much difference in the hand position during the hold time (figures below).\nIn both figures, each dot represents the average activity or hand position in one trial, with CO trials in red and CST trials in viridis (blue-green-yellow), with blue corresponding to low lambdas and yellow corresponding to high lambdas.\nThis separation was impressive, but I realized that I had mistakenly smoothed the neural activity with a 50ms wide Gaussian kernel before trimming and averaging the data. Because the kernel is non-causal, there was potentially some leakage from the initial movement phase into the apparent hold time activity. Removing the smoothing seemingly removes the easy-to-see separation in the neural space:\nThis is disappointing, but we should note two things:\n There\u0026rsquo;s significant overlap in the first few PCs of neural activity, but that doesn\u0026rsquo;t preclude the existence of a task context dimension of neural activity in a lower variance dimension. The fact that such a small change (a 50 ms smoothing kernel) can induce such a large separation in neural activity suggests that even if there\u0026rsquo;s no separation during the hold time, the neural activity separates remarkably quickly after the trial starts. We still need to investigate whether this separation is simply due to a difference in initial kinematics, but it\u0026rsquo;s possible that the early part of the trial is where the neural activity separates based on context.  So there are still avenues to pursue to extract a task context dimension of neural activity. Perhaps there\u0026rsquo;s even a separation between $\\lambdas$ in the initial period of the trial.\n"},{"id":5,"href":"/neural-analyis-notes/20211214-tangling-analysis/","title":"CO-CST tangling analysis","section":"Possible neural analyses to compare CO and CST","content":"2021/12/13 Tangling analysis #  Overall task tangling #   ❓ CST is much more feedback driven than CO. Does this show up as M1 dynamics being less apparently autonomous? That is, is neural tangling higher in CST than CO?  ✔️ Tangling doesn\u0026rsquo;t really appear to be much higher in CST than CO, suggesting that the feedback may be \u0026ldquo;predictable\u0026rdquo; most of the time. 💬 Does tangling depend on the amount of data you use to check it? Right now I\u0026rsquo;m thinking it probably does, but I can\u0026rsquo;t be sure without simulation    In Russo et al. 2018, they found that M1 exhibited low \u0026ldquo;tangling\u0026rdquo;. This metric basically measures how predictable the dynamics of neural activity are\u0026ndash;if you\u0026rsquo;re in one neural state, low tangling would indicate that the neural state on the next time point is highly consistent. On the other hand, high tangling at a particular time point indicates that the next neural state is somewhat unpredictable\u0026ndash;basically the neural trajectories that travel through or near that neural state are \u0026ldquo;tangled\u0026rdquo;. A purely autonomous neural dynamical system should exhibit low tangling (assuming we have a complete or near complete view of the neural state space)\u0026ndash;thus, high tangling should indicate that a system\u0026rsquo;s dynamics are non-autonomous, either through time-varying dynamics, or more likely, via inputs to the system.\nAs a reminder, tangling is defined as\n$$ Q(t) = \\underset{\\tau}\\max( \\dfrac {\\dot{x}{\\tau} - \\dot{x}{t}} {x_{\\tau}-x_t} ) $$\nwhere $x_{t}$ corresponds to the neural state at timepoint $t$ and $\\dot{x}_t$ corresponds to the time derivative of the neural state at time $t$. Tangling ($Q(t)$) is thus maximal when two neural states are close together, but their time derivatives are quite different.\nBecause CST is more feedback-driven than CO, you would expect that M1 neural dynamics shouldn\u0026rsquo;t be as autonomous-like in CST as we know it is in CO. This could mean that we should expect higher tangling in CST than CO. To check this, we ran an analysis of neural tangling in the 8 dimensions of neural activity that explain the most variance for both CO and CST. In both cases, we smoothed the neural activity using a Gaussian kernel with standard deviation of 75 ms and soft normalized it (with $\\alpha=5$). The time periods in which we checked tangling was between the go cue time and the end of each trial.\nPlotting an estimated probability density of tangling values for each task shows that there\u0026rsquo;s a great deal of overlap in tangling distributions, which seems quite unexpected, given how feedback driven CST is. One possibility is that including the whole trial during the CO task includes more than just the ballistic, feedforward part of the movement. In the time right after go cue, there are likely some inputs to M1 telling it which target to prepare and execute a movement for. Likewise, near the end of a CO movement, a monkey will often adjust the trajectory of the hand based on errors in the reach. Thus one modification may be to limit the CO tangling analysis to the middle portion of the trial, after movement onset and before any possible corrections.\nFrom this reduction in CO trial time, there is slightly more difference between the two task distributions, though they still overlap significantly.\nAnother possible consideration is that we search for highly tangled pairs of states in a much larger set of timepoints with CST, given that CST has 6 second trials and there are many more of them. This may artificially inflate tangling, especially in the presence of noisy neural state. We can test this by limiting the CST trials to one specific $\\lambda$ (in the following figure, $\\lambda = 3.3$, still taking only the middle part of the CO trials)\nOnce again, the distributions are highly overlapping. We\u0026rsquo;ll probably have to be careful about the amount of data we use to compute tangling going forward, or we will need to find a good way to trial average data across the CST dataset (possibly through a submovement decomposition?).\nThe fact that tangling is similar between CO and CST is quite interesting. It suggests that while CST is quite feedback-driven, the dynamics of M1 remain mostly predictable. This predictability may stem from the fact that as a whole, the monkey-CST system has predictable dynamics, apart from sensory and motor noise at the interface between the monkey and the computer. Another possibility is that M1 remains untangled most of the time, but gets tangled at times when it integrates feedback to make a motor adjustment.\nTimecourse of tangling #   ❓ Does the timecourse of tangling over a CST or CO trial reveal anything about corrective movements? Perhaps tangling increases before corrective movements or after apparent errors to signify introduction of unexpected feedback.  💬 May need to develop corrective movement detection to enable trial averaging, as well as apparent error detection (for CST, this might equate to moving the hand in the wrong direction)    If tangling is generally low in M1 because the monkey is intermittently integrating feedback information, then it may be possible to see this by looking at the timecourse of tangling through CO and CST trials.\nBelow is a representation of an example CO trial.\nIn this figure, the left column shows the timecourse of tangling (top, yellow is highest tangling), hand kinematics, and the 8 dimensions of M1 neural state. Middle column shows the hand movement in the x-y plane, with points colored by tangling (same color map as top left). Right plot shows the top three dimensions of M1 activity, colored by tangling.\nOne highly noticable aspect of this trial is the late correction that the monkey makes to stay in the final target\u0026ndash;this correction is surrounded by a period of high tangling, as we might expect. However, not all CO trials are this readily interpretable. For example, here is a trial in which tangling appears to be high during the main movement.\nMoving onto CST trials, interpretation is (as always) a little bit trickier. Below are representations of a few CST trials.\nThis representation of the trial is the same as the CO plots, with the exception that the middle plot is replaced by a sensorimotor plot, showing the hand position plotted against cursor position, highlighting the when the two are and are not in direct opposition.\nIt\u0026rsquo;s hard to say anything for sure from these plots, but it does seem like larger movements in general have lower tangling. This might be due to the neural state reaching out from the tangled ball in the center (right plot), but it\u0026rsquo;s not entirely clear. We maybe have to come up with some submovement decomposition over which to average neural traces before we can interpret tangling in this task.\nFind more figs/trials folder.\n"}]