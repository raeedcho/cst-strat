<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=theme-color content="dark">
<title>CST neural engagement analysis | CST Strategy Project Notes</title>
<meta property="og:site_name" content="CST Strategy project notes">
<meta property="og:title" content="CST neural engagement analysis | CST Strategy Project Notes">
<meta itemprop=name content="CST neural engagement analysis | CST Strategy Project Notes">
<meta name=twitter:title content="CST neural engagement analysis | CST Strategy Project Notes">
<meta name=application-name content="CST neural engagement analysis | CST Strategy Project Notes">
<meta name=description content="Notes for CST project">
<meta name=twitter:description content="Notes for CST project">
<meta itemprop=description content="Notes for CST project">
<meta property="og:description" content="Notes for CST project">
<link rel="shortcut icon" type=image/x-icon href=/cst-strat/favicon.ico>
<link rel=stylesheet href=/cst-strat/sass/main.min.ab99ff095f832511e24ffb2fba2b51ad473b2f7e9301d674eba2c6c3a6e8bd81.css>
</head>
<script>(function(){const b='ThemeColorScheme',a=localStorage.getItem(b),c=window.matchMedia('(prefers-color-scheme: dark)').matches===!0;a=='dark'||a==='auto'&&c?document.documentElement.dataset.userColorScheme='dark':document.documentElement.dataset.userColorScheme='light'})()</script>
<body class=dark>
<nav class=navbar>
<div class=container>
<div class=flex>
<div>
<a class=brand href=/cst-strat/>
CST Strategy Project Notes
</a>
</div>
<div class=flex>
<a href=/cst-strat/analysis-log/>Analysis log</a>
<button id=dark-mode-button><svg class="light" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" width="1em" height="1em" style="-ms-transform:rotate(360deg);-webkit-transform:rotate(360deg);transform:rotate(360deg)" viewBox="0 0 36 36"><path fill="#ffd983" d="M30.312.776C32 19 20 32 .776 30.312c8.199 7.717 21.091 7.588 29.107-.429C37.9 21.867 38.03 8.975 30.312.776z"/><path d="M30.705 15.915a1.163 1.163.0 101.643 1.641 1.163 1.163.0 00-1.643-1.641zm-16.022 14.38a1.74 1.74.0 000 2.465 1.742 1.742.0 100-2.465zm13.968-2.147a2.904 2.904.0 01-4.108.0 2.902 2.902.0 010-4.107 2.902 2.902.0 014.108.0 2.902 2.902.0 010 4.107z" fill="#ffcc4d"/><rect x="0" y="0" width="36" height="36" fill="rgba(0, 0, 0, 0)"/></svg><svg class="dark" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" width="1em" height="1em" style="-ms-transform:rotate(360deg);-webkit-transform:rotate(360deg);transform:rotate(360deg)" viewBox="0 0 36 36"><path fill="#ffd983" d="M16 2s0-2 2-2 2 2 2 2v2s0 2-2 2-2-2-2-2V2zm18 14s2 0 2 2-2 2-2 2h-2s-2 0-2-2 2-2 2-2h2zM4 16s2 0 2 2-2 2-2 2H2s-2 0-2-2 2-2 2-2h2zm5.121-8.707s1.414 1.414.0 2.828-2.828.0-2.828.0L4.878 8.708s-1.414-1.414.0-2.829c1.415-1.414 2.829.0 2.829.0l1.414 1.414zm21 21s1.414 1.414.0 2.828-2.828.0-2.828.0l-1.414-1.414s-1.414-1.414.0-2.828 2.828.0 2.828.0l1.414 1.414zm-.413-18.172s-1.414 1.414-2.828.0.0-2.828.0-2.828l1.414-1.414s1.414-1.414 2.828.0.0 2.828.0 2.828l-1.414 1.414zm-21 21s-1.414 1.414-2.828.0.0-2.828.0-2.828l1.414-1.414s1.414-1.414 2.828.0.0 2.828.0 2.828l-1.414 1.414zM16 32s0-2 2-2 2 2 2 2v2s0 2-2 2-2-2-2-2v-2z"/><circle fill="#ffd983" cx="18" cy="18" r="10"/><rect x="0" y="0" width="36" height="36" fill="rgba(0, 0, 0, 0)"/></svg>
</button>
</div>
</div>
</div>
</nav>
<main>
<div class=container>
<article>
<header class=article-header>
<div class=thumb>
<div>
<h1>CST neural engagement analysis</h1>
<div class=post-meta>
<div>
By Raeed Chowdhury | <time>December 10, 2021</time>
| 3 minutes
</div>
<div class=tags>
<a href=/cst-strat/tags/neural/>neural</a>
<a href=/cst-strat/tags/population/>population</a>
<a href=/cst-strat/tags/engagement/>engagement</a>
<a href=/cst-strat/tags/hold-period/>hold period</a>
</div>
</div>
</div>
</div>
</header>
</article>
<div class=article-post>
<p>‚ùì Is there a dimension of neural activity corresponding to neural engagement? Perhaps something that corresponds to whether $\lambda$ changed on the last trial, or whether there have been previous failures?</p>
<p>In <a href=https://doi.org/10.1038/s41593-021-00822-8>Hennig et al. 2021</a>, they found a neural dimension corresponding to engagement with the BCI task. When there were changes in the task (e.g. the decoder changes), activity along this axis increases and then slowly decreases over a series of trials.</p>
<p>They found this axis separately for each target direction during a BCI center-out task&ndash;they defined it as the dimension along which neural activity had the most variance for trials to that specific target. This also happened to line up nicely with the &ldquo;ones&rdquo; axis, the axis along which most, if not all, neural loadings were positive and similar to each other.</p>
<p>Aaron has a vague memory of a previous master&rsquo;s student finding some kind of change in neural activity after $\lambda$ changed in CST&ndash;might there be a neural engagement signal in this task too?</p>
<p>Since we don&rsquo;t really have targets in CST, our next best bet was to look at the activity during the hold period&ndash;perhaps there would be some large variance dimensions of neural activity that could correspond to whether the $\lambda$ changed within the last couple trials, or the number of previous failures in the task. Below are figures plotting the first three PCs of average hold time activity during CST (note: neural activity was softnormed here)</p>
<p><img loading=lazy src=/cst-strat/log/2021/12/engagement-analysis/figs/20211206_Earl20190716_holdPCActivity.png alt="Earl hold time PCA activity" width=823 height=625></p>
<p><img loading=lazy src=/cst-strat/log/2021/12/engagement-analysis/figs/20211206_Ford20180627_holdPCActivity.png alt="Ford hold time PCA activity" width=774 height=611></p>
<p>In these figures, top plot shows the $\lambda$ for each trial as a color (where the actual value is given by the color bar at the top&mldr; it&rsquo;s a little confusing). The red dashed lines indicate trials on which the monkey failed the task. Other three plots show average hold time activity in PC 1, 2, or 3, where each dot represents one trial, colored by its $\lambda$. For Earl, there seems to be a slow drift in PC1 , possibly related to lambda changes or failures, but it could also be related to disinterest in the task&ndash;hard to say without randomized $\lambda$. Other than that, I can&rsquo;t really see a correspondence between hold time activity and $\lambda$ changes or failures.</p>
<p>One way to check this out a bit more is to try to predict either the $\lambda$ on the previous trial or the number of previous failures from the hold time activity. Figures below:</p>
<p><img loading=lazy src=/cst-strat/log/2021/12/engagement-analysis/figs/20211206_Earl20190716_hold_prevlambda_prediction.png alt="Earl hold time lambda prediction" width=560 height=420></p>
<p><img loading=lazy src=/cst-strat/log/2021/12/engagement-analysis/figs/20211206_Ford20180627_hold_prevlambda_prediction.png alt="Ford hold time lambda prediction" width=560 height=420></p>
<p>Again, slight correlation in Earl with $\lambda$ on previous trial, but this might be due to the slow drift.</p>
<p><img loading=lazy src=/cst-strat/log/2021/12/engagement-analysis/figs/20211206_Earl20190716_hold_prevfailure_prediction.png alt="Earl hold time failure prediction" width=560 height=420></p>
<p><img loading=lazy src=/cst-strat/log/2021/12/engagement-analysis/figs/20211206_Ford20180627_hold_prevfailure_prediction.png alt="Ford hold time failure prediction" width=560 height=420></p>
<p>No real correlation here unfortunately.</p>
<p>One possible followup for this engagement work is just to look at the mean firing rate across neurons for each trial to see if there&rsquo;s anything that jumps out&ndash;since the engagement axis in the Hennig paper was mainly in the &ldquo;ones&rdquo; axis, maybe a straight average across normed neurons will pull something from the noise.</p>
<p>If we try to look for engagement in neural population during the movement phase of CST, one thing we might have to contend with is the monkey&rsquo;s arm movements (which weren&rsquo;t present in the BCI task in the Hennig paper), but perhaps we can just fit a linear model between neural activity and arm movement and then just look at the null space of that to take out the majority of arm-related neural signals.</p>
</div>
</div>
<div class=container>
<nav class="flex container suggested">
<a rel=prev href=/cst-strat/log/2021/12/cis-analysis/ title="Previous post (older)">
<span>Previous</span>
CO Condition independent signal analysis
</a>
<a rel=next href=/cst-strat/log/2021/12/hold-analysis/ title="Next post (newer)">
<span>Next</span>
CO-CST hold time analysis
</a>
</nav>
</div>
<div class=container>
<script src=https://giscus.app/client.js data-repo=raeedcho/cst-strat data-repo-id="MDEwOlJlcG9zaXRvcnkzMjkxNDc2NTU=" data-category=Comments data-category-id=DIC_kwDOE55lB84CAVLz data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=light crossorigin=anonymous async></script>
<script>function setGiscusTeheme(b){let a=document.querySelector('.giscus iframe');a&&a.contentWindow.postMessage({giscus:{setConfig:{theme:b}}},'https://giscus.app')}addEventListener('message',a=>{if(a.origin!=='https://giscus.app')return;setGiscusTeheme(document.documentElement.dataset.userColorScheme)}),window.addEventListener('onColorSchemeChange',a=>{setGiscusTeheme(a.detail)})</script>
</div>
</main>
</main>
<footer class="footer flex">
<section class=container>
<nav class=footer-links>
</nav>
</section>
<script defer src=/cst-strat/ts/features.a534d05c446023fa2ae2a638f87cc2443ad8e49f6aaeb4d9f24ed61d53766712.js data-enable-footnotes=true></script>
</footer>
</body>
</html>