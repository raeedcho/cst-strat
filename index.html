<!doctype html><html lang=en-us>
<head>
<meta name=generator content="Hugo 0.91.0">
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1">
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=theme-color content="dark">
<title>Analysis brainstorming | CST Strategy Project Notes</title>
<meta property="og:site_name" content="CST Strategy project notes">
<meta property="og:title" content="Analysis brainstorming | CST Strategy Project Notes">
<meta itemprop=name content="Analysis brainstorming | CST Strategy Project Notes">
<meta name=twitter:title content="Analysis brainstorming | CST Strategy Project Notes">
<meta name=application-name content="Analysis brainstorming | CST Strategy Project Notes">
<meta name=description content="Notes for CST project">
<meta name=twitter:description content="Notes for CST project">
<meta itemprop=description content="Notes for CST project">
<meta property="og:description" content="Notes for CST project">
<link rel="shortcut icon" type=image/x-icon href=/cst-strat/favicon.ico>
<link rel=stylesheet href=/cst-strat/sass/main.min.ab99ff095f832511e24ffb2fba2b51ad473b2f7e9301d674eba2c6c3a6e8bd81.css>
</head>
<script>(function(){const b='ThemeColorScheme',a=localStorage.getItem(b),c=window.matchMedia('(prefers-color-scheme: dark)').matches===!0;a=='dark'||a==='auto'&&c?document.documentElement.dataset.userColorScheme='dark':document.documentElement.dataset.userColorScheme='light'})()</script>
<body class=dark>
<nav class=navbar>
<div class=container>
<div class=flex>
<div>
<a class=brand href=/cst-strat/>
CST Strategy Project Notes
</a>
</div>
<div class=flex>
<a href=/cst-strat/analysis-log/>Analysis log</a>
<button id=dark-mode-button><svg class="light" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" width="1em" height="1em" style="-ms-transform:rotate(360deg);-webkit-transform:rotate(360deg);transform:rotate(360deg)" viewBox="0 0 36 36"><path fill="#ffd983" d="M30.312.776C32 19 20 32 .776 30.312c8.199 7.717 21.091 7.588 29.107-.429C37.9 21.867 38.03 8.975 30.312.776z"/><path d="M30.705 15.915a1.163 1.163.0 101.643 1.641 1.163 1.163.0 00-1.643-1.641zm-16.022 14.38a1.74 1.74.0 000 2.465 1.742 1.742.0 100-2.465zm13.968-2.147a2.904 2.904.0 01-4.108.0 2.902 2.902.0 010-4.107 2.902 2.902.0 014.108.0 2.902 2.902.0 010 4.107z" fill="#ffcc4d"/><rect x="0" y="0" width="36" height="36" fill="rgba(0, 0, 0, 0)"/></svg><svg class="dark" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" focusable="false" width="1em" height="1em" style="-ms-transform:rotate(360deg);-webkit-transform:rotate(360deg);transform:rotate(360deg)" viewBox="0 0 36 36"><path fill="#ffd983" d="M16 2s0-2 2-2 2 2 2 2v2s0 2-2 2-2-2-2-2V2zm18 14s2 0 2 2-2 2-2 2h-2s-2 0-2-2 2-2 2-2h2zM4 16s2 0 2 2-2 2-2 2H2s-2 0-2-2 2-2 2-2h2zm5.121-8.707s1.414 1.414.0 2.828-2.828.0-2.828.0L4.878 8.708s-1.414-1.414.0-2.829c1.415-1.414 2.829.0 2.829.0l1.414 1.414zm21 21s1.414 1.414.0 2.828-2.828.0-2.828.0l-1.414-1.414s-1.414-1.414.0-2.828 2.828.0 2.828.0l1.414 1.414zm-.413-18.172s-1.414 1.414-2.828.0.0-2.828.0-2.828l1.414-1.414s1.414-1.414 2.828.0.0 2.828.0 2.828l-1.414 1.414zm-21 21s-1.414 1.414-2.828.0.0-2.828.0-2.828l1.414-1.414s1.414-1.414 2.828.0.0 2.828.0 2.828l-1.414 1.414zM16 32s0-2 2-2 2 2 2 2v2s0 2-2 2-2-2-2-2v-2z"/><circle fill="#ffd983" cx="18" cy="18" r="10"/><rect x="0" y="0" width="36" height="36" fill="rgba(0, 0, 0, 0)"/></svg>
</button>
</div>
</div>
</div>
</nav>
<main>
<div class=container>
<article>
<header class=article-header>
<div class=thumb>
<div>
<h1>Analysis brainstorming</h1>
<div class=post-meta>
<div>
By Raeed Chowdhury | <time>December 01, 2021</time>
| 5 minutes
</div>
<div class=tags>
</div>
</div>
</div>
</div>
</header>
</article>
<div class=article-post>
<p>Below is a broad list of all the analyses that we might run on CST data. The main focus is on neural analyses, which themselves are primarily focused on comparing CST and CO data, but I&rsquo;ve also included a short section on behavioral analyses that could help us understand and contextualize the neural analysis results.</p>
<p>If you want to see a log of some of the analyses that I&rsquo;ve run on the data, check out the <a href=analysis-log/>Analysis log</a>!</p>
<p>If you have some ideas on analyses that aren&rsquo;t listed below, leave a comment at the bottom of the article (requires GitHub account), or send me an email.</p>
<h2 id=neural-analyses>
<a href=#neural-analyses class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>
Neural analyses
</h2>
<h3 id=single-neuron-analyses>
<a href=#single-neuron-analyses class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>
Single neuron analyses
</h3>
<p>List of analyses that we can use to compare CO and CST on a single neuron level</p>
<ul>
<li>Averages
<ul>
<li>❓ How does average firing rate change across tasks?
<ul>
<li>📊 Analysis: compare averages across tasks</li>
</ul>
</li>
<li>❓ How does average firing rate change between hold and movement, within and across tasks?
<ul>
<li>📊 Analysis: Hold vs. move activity within and across tasks</li>
</ul>
</li>
</ul>
</li>
<li>PSTHs
<ul>
<li>❓ Do PSTHs in CST look like CO?
<ul>
<li>📊 Analysis: Calculate PSTHs for hold->move submovements in CST</li>
</ul>
</li>
</ul>
</li>
<li>Tuning curves
<ul>
<li>❓ How similar is single neural tuning between CO and CST?
<ul>
<li>📊 Analysis: Compare left/right selectivity between CO and CST
<ul>
<li>✔️ Note: This is basically the sensorimotor index analysis, which showed similar tuning between the tasks</li>
</ul>
</li>
<li>📊 Analysis: Fit GLMs and examine how parameters shift between CO and CST
<ul>
<li>❗ Note/caution: neural GLMs are usually noisy and tricky to glean interpretation from</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id=population-analyses>
<a href=#population-analyses class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>
Population analyses
</h3>
<p>List of population analysis methods we could use to compare CO and CST</p>
<ul>
<li>Neural covariance
<ul>
<li>❓ Because CST has smaller movements, does neural variance also decrease as much as you would expect?
<ul>
<li>📊 Analysis: compare total neural variance between CO and CST</li>
<li>✔️ CST usually has smaller variance than CO, but unclear yet if it&rsquo;s what we would expect from smaller movements</li>
<li>❓ Remiaining question: is this variance solely due to smaller movements? Not sure how to address this question though.</li>
</ul>
</li>
<li>❓ CST seems like a more complex task than CO&ndash;does this mean that neural activity explores more dimensions?
<ul>
<li>📊 compare CO and CST covariance rank (i.e. dimensionality)
<ul>
<li>✔️ CST does not seem to have much higher dimensionality, but activity is much closer to noise floor</li>
<li>💬 Three methods of dimensionality estimation (participation ratio, parallel analysis, and GPFA cross-validated log-likelihood) give differing results</li>
</ul>
</li>
</ul>
</li>
<li>❓ How much do CST and CO overlap in the neural manifold?
<ul>
<li>📊 compare neural covariance dimensions between CO and CST, using subspace overlap or principle angles</li>
</ul>
</li>
</ul>
</li>
<li>Subspace analysis
<ul>
<li>❓ Is there a neural &ldquo;go&rdquo; signal underlying intermittent movements/control?
<ul>
<li>📊 Condition independent signal analysis
<ul>
<li>💬 It&rsquo;s difficult to pull out a meaningful CIS at a single trial level, even for CO task. We probably need a method for trial-averaging CST to make use of this (like submovement decomposition)</li>
</ul>
</li>
</ul>
</li>
<li>❓ is there a dimension of neural activity corresponding to neural engagement? Perhaps something that corresponds to whether $\lambda$ changed on the last trial, or whether there have been previous failures?
<ul>
<li>📊 Analyze major neural dimensions during hold period after failures and $\lambda$ changes</li>
</ul>
</li>
<li>📊 Behaviorally potent/null space analysis
<ul>
<li>❓ Do CO and CST share a kinematic potent space? (use principle angles and subspace alignment)
<ul>
<li>✔️ Sudarshan&rsquo;s and my own analysis suggests that potent spaces are at least partially aligned</li>
</ul>
</li>
<li>❓ How much neural variance lies in the potent and null spaces of each task, compared to total neural variance?</li>
<li>❓ Is there any correspondence between the timing of null space activation and movement?
<ul>
<li>💬 Note: our arrays don&rsquo;t seem to have preparatory activity, which is what you&rsquo;d expect to find in the null space. But there may be some information about visual feedback, if we can isolate feedback integration times</li>
</ul>
</li>
<li>❓ What does the null space activity look like during BCI CST, where potent space is specified?
<ul>
<li>💬 Aaron says that BCI data might not be great? Need to check with Emily</li>
</ul>
</li>
</ul>
</li>
<li>❓ Are there dimensions of neural activity that separate CO and CST?
<ul>
<li>✔️ Hold time analysis says possibly in the very early part of the movement, but perhaps this is due to kinematic differences?</li>
<li>❓ if there&rsquo;s a task context dimension, how aligned with kinematic potent space is it? Perhaps this dimension separates different motor cortical dynamic regimes?</li>
</ul>
</li>
</ul>
</li>
<li>Neural dynamics
<ul>
<li>📊 Tangling analysis
<ul>
<li>❓ CST is much more feedback driven than CO. Does this show up as M1 dynamics being less apparently autonomous? That is, is neural tangling higher in CST than CO?
<ul>
<li>✔️ Tangling doesn&rsquo;t really appear to be much higher in CST than CO, suggesting that the feedback may be &ldquo;predictable&rdquo; most of the time.</li>
<li>💬 Does tangling depend on the amount of data you use to check it? Right now I&rsquo;m thinking it probably does, but I can&rsquo;t be sure without simulation</li>
</ul>
</li>
<li>❓ Does the timecourse of tangling over a CST or CO trial reveal anything about corrective movements? Perhaps tangling increases before corrective movements or after apparent errors to signify introduction of unexpected feedback.
<ul>
<li>💬 May need to develop corrective movement detection to enable trial averaging, as well as apparent error detection (for CST, this might equate to moving the hand in the wrong direction)</li>
</ul>
</li>
</ul>
</li>
<li>📊 Neural dynamic modeling
<ul>
<li>❓ Does CST contain different neural dynamical regimes? e.g. movement vs. hold/preparation
<ul>
<li>❗ CO seems to have different regimes, according to previous work, but CST data seems a bit too noisy as is</li>
</ul>
</li>
<li>❓ Does CST have autonomous and input-driven times in neural dynamics? That is, if we infer inputs to a neural dynamical system (AutoLFADS), do the inputs look similar between movement initiation and submovements?
<ul>
<li>💬 Other work suggests movement initiation and corrective movements share features like condition independent signal and inferred inputs</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id=behavioral-analyses>
<a href=#behavioral-analyses class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>
Behavioral analyses
</h2>
<ul>
<li>Inferrential
<ul>
<li>❓ We see an apparent &ldquo;act and wait&rdquo; type behavior in monkeys performing CST&ndash;they often don&rsquo;t respond to small cursor velocities. Can we decompose a subject&rsquo;s behavior into a set of submovements?
<ul>
<li>📊 Simple act and wait hidden markov model</li>
<li>📊 Switching controller strategy</li>
</ul>
</li>
</ul>
</li>
<li>Generative
<ul>
<li>❓ What normative principles are necessary for a generative model to recapitulate the behavior of a subject (human or monkey) performing CST?
<ul>
<li>📊 Optimal feedback control (Mohsen)</li>
<li>📊 Reinforcement learning (Joel)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id=cross-over-analyses>
<a href=#cross-over-analyses class=anchor><svg class="icon" aria-hidden="true" focusable="false" height="16" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>
</a>
Cross-over analyses
</h2>
<p>List of sophisticated behavioral analyses that could be run on neural data</p>
<ul>
<li>📊 Contraction analysis</li>
</ul>
</div>
</div>
<div class=container>
</div>
<div class=container>
<script src=https://giscus.app/client.js data-repo=raeedcho/cst-strat data-repo-id="MDEwOlJlcG9zaXRvcnkzMjkxNDc2NTU=" data-category=Comments data-category-id=DIC_kwDOE55lB84CAVLz data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=0 data-theme=light crossorigin=anonymous async></script>
<script>function setGiscusTeheme(b){let a=document.querySelector('.giscus iframe');a&&a.contentWindow.postMessage({giscus:{setConfig:{theme:b}}},'https://giscus.app')}addEventListener('message',a=>{if(a.origin!=='https://giscus.app')return;setGiscusTeheme(document.documentElement.dataset.userColorScheme)}),window.addEventListener('onColorSchemeChange',a=>{setGiscusTeheme(a.detail)})</script>
</div>
</main>
</main>
<footer class="footer flex">
<section class=container>
<nav class=footer-links>
</nav>
</section>
<script defer src=/cst-strat/ts/features.a534d05c446023fa2ae2a638f87cc2443ad8e49f6aaeb4d9f24ed61d53766712.js data-enable-footnotes=true></script>
</footer>
</body>
</html>